{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## final model :\n",
    "(Test-4, from Accident_Classifier_Model_Selection.ipynb)\n",
    "\n",
    "Model: resnet18\n",
    "\n",
    "Learning Rate: 0.001\n",
    "\n",
    "Batch Size: 32\n",
    "\n",
    "Activation Function: LeakyReLU\n",
    "\n",
    "Epochs: 10"
   ],
   "id": "3ceae27d46e5fe95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T05:04:19.215176Z",
     "start_time": "2025-06-23T05:04:01.075351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Final accident classifier script locked to best configuration (Test 4)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision.models import resnet18"
   ],
   "id": "6a18d68122a052d4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Paths\n",
    "DATA_DIR = \"/content/drive/MyDrive/unified_data\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Best configuration (from Test 4)\n",
    "ARCH = \"resnet18\"\n",
    "LR = 0.001\n",
    "BATCH_SIZE = 32\n",
    "ACTIVATION_FN = nn.LeakyReLU\n",
    "EPOCHS = 10\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset\n",
    "full_dataset = datasets.ImageFolder(DATA_DIR, transform=transform)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size], generator=generator)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# Model definition\n",
    "def get_model():\n",
    "    model = resnet18(weights=\"DEFAULT\")\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(num_features, 256),\n",
    "        ACTIVATION_FN(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(256, 2)\n",
    "    )\n",
    "    return model.to(DEVICE)\n",
    "\n",
    "model = get_model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "    loop = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for i, (images, labels) in loop:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (preds == labels).sum().item()\n",
    "\n",
    "        avg_loss = train_loss / train_total if train_total > 0 else 0.0\n",
    "        avg_acc = train_correct / train_total if train_total > 0 else 0.0\n",
    "        loop.set_postfix(train_loss=avg_loss, train_acc=avg_acc)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_preds, val_labels = [], []\n",
    "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "\n",
    "    val_acc = val_correct / val_total\n",
    "    avg_val_loss = val_loss / val_total\n",
    "    print(f\" Epoch {epoch+1} Summary: Train Acc: {avg_acc:.4f}, Train Loss: {avg_loss:.4f}, Val Acc: {val_acc:.4f}, Val Loss: {avg_val_loss:.4f}\")"
   ],
   "id": "166d4ff8548fbc4e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"accident_classifier_resnet18.pth\")\n",
    "print(\" Model saved as accident_classifier_resnet18.pth\")"
   ],
   "id": "47ba787b22df5b53"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
